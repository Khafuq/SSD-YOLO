{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "xOPrqZNDJPBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b41e61e-1b63-44ac-979b-b156c29efb45"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\" -O vehicle-counting.mp4 && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "73DJTqwRIutb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8727b7-3649-4d80-ab02-717dd799ed7c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2024-02-08 18:45:42--  https://docs.google.com/uc?export=download&confirm=&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.96.138, 108.177.96.101, 108.177.96.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.96.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-&export=download [following]\n",
            "--2024-02-08 18:45:43--  https://drive.usercontent.google.com/download?id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.96.132, 2a00:1450:4013:c06::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.96.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35345757 (34M) [video/mp4]\n",
            "Saving to: ‘vehicle-counting.mp4’\n",
            "\n",
            "vehicle-counting.mp 100%[===================>]  33.71M   217MB/s    in 0.2s    \n",
            "\n",
            "2024-02-08 18:45:44 (217 MB/s) - ‘vehicle-counting.mp4’ saved [35345757/35345757]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B49rMDnhIvmU",
        "outputId": "605c0be5-db5f-4534-d85e-2b659dc0c20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.1.10)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd {HOME}/ByteTrack\n",
        "\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
        "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
        "\n",
        "!pip3 install -q -r requirements.txt\n",
        "!python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/112 and https://github.com/roboflow/notebooks/issues/106\n",
        "!pip install -q loguru lap thop\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ],
      "metadata": {
        "id": "-LhsN_rcIxxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ],
      "metadata": {
        "id": "O379N3q8Iz03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision==0.1.0\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import supervision\n",
        "print(\"supervision.__version__:\", supervision.__version__)"
      ],
      "metadata": {
        "id": "oUROIDUiI2iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator"
      ],
      "metadata": {
        "id": "g0pAz230I5Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and download the video"
      ],
      "metadata": {
        "id": "iBLHG9CBrj7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "from typing import List\n",
        "import sys\n",
        "\n",
        "HOME = os.getcwd()\n",
        "print(HOME)\n",
        "%cd {HOME}\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\" -O vehicle-counting.mp4 && rm -rf /tmp/cookies.txt\n",
        "\n",
        "# Load the YOLOv5 model\n",
        "model = YOLO('yolov5su.pt')"
      ],
      "metadata": {
        "id": "68zDUjF9Q9ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two main methods to get the color and position the tracker at the objects(Don't read them just use them)"
      ],
      "metadata": {
        "id": "wov9BE1rrP5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis]\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections,\n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    tracker_ids = [None] * len(detections)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ],
      "metadata": {
        "id": "407aDg61jJqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def get_dominant_color(image, k=3):\n",
        "    \"\"\"\n",
        "    Find the dominant color in an image using k-means clustering in the HSV color space.\n",
        "\n",
        "    :param image: Image from which to get the dominant color (in BGR format).\n",
        "    :param k: Number of clusters for k-means clustering.\n",
        "    :return: Dominant color in HSV format.\n",
        "    \"\"\"\n",
        "    # Convert to HSV\n",
        "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    pixels = image_hsv.reshape((-1, 3))\n",
        "\n",
        "    # Perform k-means clustering with an explicit n_init value\n",
        "    clt = KMeans(n_clusters=k, n_init=10)  # Explicitly set n_init to suppress the warning\n",
        "    clt.fit(pixels)\n",
        "\n",
        "    # Assume the cluster with the highest weight has the dominant color\n",
        "    hist = np.bincount(clt.labels_)\n",
        "    dominant_color = clt.cluster_centers_[hist.argmax()]\n",
        "\n",
        "    return dominant_color\n",
        "\n",
        "\n",
        "def map_color_to_category(color_hsv):\n",
        "    \"\"\"\n",
        "    Map an HSV color to a predefined color category, with improved handling for black and white.\n",
        "\n",
        "    :param color_hsv: Color in HSV format (Hue, Saturation, Value).\n",
        "    :return: Color category as a string.\n",
        "    \"\"\"\n",
        "    # Handling for black and white\n",
        "    if color_hsv[2] <= 50 and color_hsv[1] <= 50:  # Black: low value and saturation\n",
        "        return \"black\"\n",
        "    elif color_hsv[2] >= 200 and color_hsv[1] <= 25:  # White: high value and low saturation\n",
        "        return \"white\"\n",
        "\n",
        "    # Define color ranges in HSV format for other colors\n",
        "    color_ranges = {\n",
        "        \"red\": ((0, 50, 50), (10, 255, 255)),\n",
        "        \"blue\": ((110, 50, 50), (130, 255, 255)),\n",
        "        \"green\": ((50, 50, 50), (70, 255, 255)),\n",
        "    }\n",
        "\n",
        "    for color_name, (lower, upper) in color_ranges.items():\n",
        "        lower = np.array(lower, dtype=np.uint8)\n",
        "        upper = np.array(upper, dtype=np.uint8)\n",
        "        if cv2.inRange(np.array([[color_hsv]], dtype=np.uint8), lower, upper).any():\n",
        "            return color_name\n",
        "\n",
        "    return \"unknown\"\n",
        "\n",
        "def get_car_color(frame, bbox):\n",
        "    \"\"\"\n",
        "    Determine the car's color from a video frame and bounding box.\n",
        "\n",
        "    :param frame: The video frame (in BGR format).\n",
        "    :param bbox: The bounding box of the detected car (in xyxy format).\n",
        "    :return: The car's color as a string.\n",
        "    \"\"\"\n",
        "    # Extract the region of interest from the frame\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    roi = frame[y1:y2, x1:x2]\n",
        "\n",
        "    # Get the dominant color in the ROI\n",
        "    dominant_color = get_dominant_color(roi, k=3)\n",
        "\n",
        "    # Map the dominant color to a color category\n",
        "    color_category = map_color_to_category(dominant_color)\n",
        "\n",
        "    return color_category"
      ],
      "metadata": {
        "id": "ZdO41vpdWtDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read video and make predictions + output the video"
      ],
      "metadata": {
        "id": "9dGSYYaLreav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "CLASS_ID = [2, 3, 5, 7]"
      ],
      "metadata": {
        "id": "8-oVmXYkNcOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the targeted video\n",
        "SOURCE_VIDEO_PATH = './vehicle-counting.mp4'\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
      ],
      "metadata": {
        "id": "WX_lyyS8aVt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# settings\n",
        "LINE_START = Point(50, 1500)\n",
        "LINE_END = Point(3840-50, 1500)\n",
        "TARGET_VIDEO_PATH = f\"{HOME}/vehicle-counting-result.mp4\""
      ],
      "metadata": {
        "id": "oc5ljcN1CoJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate the tracker to track cars because yolo doesn't track car(tracker will give each car an ID)\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "\n",
        "# create frame generator\n",
        "generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create LineCounter instance to count the ins and outs\n",
        "# First we need to set the line parameters based on the video's h,w\n",
        "line_counter = LineCounter(start=LINE_START, end=LINE_END)\n",
        "\n",
        "# create VideoInfo instance\n",
        "video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create instance of BoxAnnotator and LineCounterAnnotator\n",
        "line_annotator = LineCounterAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "TARGET_VIDEO_PATH = f'{HOME}/counted_output_video.mp4'\n",
        "color_counts = {}\n",
        "tracked_car_ids = set()\n",
        "# open target video file\n",
        "with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n",
        "    # loop over video frames\n",
        "    for frame in tqdm(generator, total=video_info.total_frames):\n",
        "      # create instance of BoxAnnotator\n",
        "      box_annotator = BoxAnnotator(color=ColorPalette(), thickness=1, text_thickness=1, text_scale=1)\n",
        "\n",
        "      # Make predictions\n",
        "      results = model(frame)\n",
        "\n",
        "      # model prediction on single frame and conversion to supervision Detections\n",
        "      # This will prepare the boxes to be added to the frame\n",
        "      detections = Detections(\n",
        "          xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "          confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "          class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "      )\n",
        "      # tracking detections\n",
        "      tracks = byte_tracker.update(\n",
        "          output_results=detections2boxes(detections=detections),\n",
        "          img_info=frame.shape,\n",
        "          img_size=frame.shape\n",
        "      )\n",
        "      # Add the trackers numbers\n",
        "      tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "      detections.tracker_id = np.array(tracker_id)\n",
        "\n",
        "      # format custom labels with car color\n",
        "      labels = [\n",
        "          f\"#{tracker_id}: {CLASS_NAMES_DICT[class_id]}, {get_car_color(frame, bbox)} {confidence:0.2f}\"\n",
        "          for bbox, confidence, class_id, tracker_id in zip(detections.xyxy, detections.confidence, detections.class_id, detections.tracker_id)\n",
        "      ]\n",
        "\n",
        "\n",
        "      for bbox, confidence, class_id, tracker_id in zip(detections.xyxy, detections.confidence, detections.class_id, detections.tracker_id):\n",
        "          if tracker_id not in tracked_car_ids:\n",
        "              color = get_car_color(frame, bbox)\n",
        "              color_counts[color] = color_counts.get(color, 0) + 1\n",
        "              tracked_car_ids.add(tracker_id)\n",
        "              label = f\"#{tracker_id}: {CLASS_NAMES_DICT[class_id]}, {color} {confidence:0.2f}\"\n",
        "\n",
        "      # updating line counter\n",
        "      line_counter.update(detections=detections)\n",
        "\n",
        "      # annotate and display frame\n",
        "      frame = box_annotator.annotate(frame=frame, detections=detections, labels=labels)\n",
        "      line_annotator.annotate(frame=frame, line_counter=line_counter)\n",
        "      sink.write_frame(frame)\n",
        "\n",
        "print(\"Color counts:\")\n",
        "for color, count in color_counts.items():\n",
        "    print(f\"{color}: {count}\")"
      ],
      "metadata": {
        "id": "BsbwN8Y8T_Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njTWaqPI_Pez"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}