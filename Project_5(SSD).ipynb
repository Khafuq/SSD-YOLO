{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and loading needed libraries"
      ],
      "metadata": {
        "id": "LEL2Infi7haM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision==0.1.0\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "import supervision"
      ],
      "metadata": {
        "id": "T6-VQQx0vWxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DatumLearning/SSD_using_OpenCV.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lQvubU6vwH6",
        "outputId": "c11c4d19-8b22-49a4-8338-c753be671912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'SSD_using_OpenCV' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)\n",
        "%cd {HOME}\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\" -O vehicle-counting.mp4 && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFEt_4vFv3XZ",
        "outputId": "e5762281-8a7e-472b-b19f-3582480dc1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n",
            "--2024-02-11 09:14:57--  https://docs.google.com/uc?export=download&confirm=&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.143.100, 74.125.143.139, 74.125.143.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.143.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-&export=download [following]\n",
            "--2024-02-11 09:14:58--  https://drive.usercontent.google.com/download?id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.18.132, 2a00:1450:4013:c18::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.18.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35345757 (34M) [video/mp4]\n",
            "Saving to: ‘vehicle-counting.mp4’\n",
            "\n",
            "vehicle-counting.mp 100%[===================>]  33.71M   205MB/s    in 0.2s    \n",
            "\n",
            "2024-02-11 09:14:59 (205 MB/s) - ‘vehicle-counting.mp4’ saved [35345757/35345757]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import webcolors\n",
        "from scipy.spatial.distance import cdist\n",
        "import matplotlib.pyplot as plt\n",
        "from supervision.draw.color import ColorPalette\n",
        "from supervision.geometry.dataclasses import Point\n",
        "from supervision.video.dataclasses import VideoInfo\n",
        "from supervision.video.source import get_video_frames_generator\n",
        "from supervision.video.sink import VideoSink\n",
        "from supervision.notebook.utils import show_frame_in_notebook\n",
        "from supervision.tools.detections import Detections, BoxAnnotator\n",
        "from supervision.tools.line_counter import LineCounter, LineCounterAnnotator\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "EhUgzhw17ozC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methods to detect color"
      ],
      "metadata": {
        "id": "lK1YmaLY7pam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dominant_color(image, k=5):\n",
        "\n",
        "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    pixels = image_hsv.reshape((-1, 3))\n",
        "\n",
        "    clt = KMeans(n_clusters=k, n_init=25)\n",
        "    clt.fit(pixels)\n",
        "\n",
        "    hist = np.bincount(clt.labels_)\n",
        "    dominant_color = clt.cluster_centers_[hist.argmax()]\n",
        "\n",
        "    return dominant_color\n",
        "\n",
        "\n",
        "def map_color_to_category(color_hsv):\n",
        "\n",
        "    color_ranges = {\n",
        "        \"red\": ((0, 50, 50), (10, 255, 255)),\n",
        "        \"blue\": ((110, 50, 50), (130, 255, 255)),\n",
        "        \"green\": ((50, 50, 50), (70, 255, 255)),\n",
        "        'white': ((0, 0, 200), (180, 25, 255)),\n",
        "        'black': ((0, 0, 0), (180, 255, 50)),\n",
        "    }\n",
        "\n",
        "    for color_name, (lower, upper) in color_ranges.items():\n",
        "        lower = np.array(lower, dtype=np.uint8)\n",
        "        upper = np.array(upper, dtype=np.uint8)\n",
        "        if cv2.inRange(np.array([[color_hsv]], dtype=np.uint8), lower, upper).any():\n",
        "            return color_name\n",
        "\n",
        "    return \"unknown\"\n",
        "\n",
        "def get_car_color(frame, bbox):\n",
        "\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    roi = frame[y1:y2, x1:x2]\n",
        "\n",
        "\n",
        "    dominant_color = get_dominant_color(roi, k=5)\n",
        "\n",
        "\n",
        "    color_category = map_color_to_category(dominant_color)\n",
        "\n",
        "    return color_category"
      ],
      "metadata": {
        "id": "BWf3Kvma7u0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loop helper to display detected colors"
      ],
      "metadata": {
        "id": "SXzVUley7vhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_color_counts_display(frame, color_counts, display_start_pos):\n",
        "    for i, (color, count) in enumerate(color_counts.items()):\n",
        "        text_color = (255, 255, 255)\n",
        "        cv2.putText(frame, f\"{color}: {count}\", (display_start_pos[0], display_start_pos[1] + 60 * i), cv2.FONT_HERSHEY_SIMPLEX, 2, text_color, 2)"
      ],
      "metadata": {
        "id": "lgcTgMti75ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variables declaration"
      ],
      "metadata": {
        "id": "tsnZKlgd76Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To keep track on cars\n",
        "tracked_cars = []\n",
        "car_id_counter = 0\n",
        "\n",
        "# To keep track on colors\n",
        "color_counts = {}\n",
        "tracked_car_ids = set()\n",
        "\n",
        "\n",
        "TARGET_VIDEO_PATH = '/content/vehicle-counting.mp4'"
      ],
      "metadata": {
        "id": "OrroRxOd7-1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the model and preparing the model"
      ],
      "metadata": {
        "id": "i-oHONJC8EPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "proto = \"./SSD_using_OpenCV/MobileNetSSD_deploy.prototxt\"\n",
        "weights = \"./SSD_using_OpenCV/MobileNetSSD_deploy.caffemodel\"\n",
        "net = cv2.dnn.readNetFromCaffe(proto, weights)"
      ],
      "metadata": {
        "id": "ry0eMqLn8H8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detection classes of intrest\n",
        "class_names_dict = {\"2\": \"car\", \"7\": \"truck\"}\n",
        "class_ids = [2,7]"
      ],
      "metadata": {
        "id": "TaWnsy_F8Vdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenCV preperation"
      ],
      "metadata": {
        "id": "jmQQJhJj8ZCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings\n",
        "cap = cv2.VideoCapture(TARGET_VIDEO_PATH)\n",
        "\n",
        "# Input video info\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Output video settings\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('/content/output_video.mp4', fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# For tqdm to display the progress as for the total\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
      ],
      "metadata": {
        "id": "9bE0ps3t8cPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looping and counting objects\n",
        "## -Creating and reading the video\n",
        "## -Tracking objects"
      ],
      "metadata": {
        "id": "Miw-jKnW8s4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMw1a7dEvVep",
        "outputId": "fa4cc0bd-1374-45b3-b9aa-0efdb22c76cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Video Frames: 100%|██████████| 538/538 [51:54<00:00,  5.79s/it]\n"
          ]
        }
      ],
      "source": [
        "for _ in tqdm(range(total_frames), desc=\"Processing Video Frames\"):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_resized = cv2.resize(frame, (300, 300))\n",
        "    blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (300, 300), (127.5, 127.5, 127.5), False)\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "\n",
        "    current_frame_detections = []\n",
        "\n",
        "    for i in range(detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence > 0.1:\n",
        "            class_id = int(detections[0, 0, i, 1])\n",
        "            if class_id in [2, 7]:\n",
        "                box = detections[0, 0, i, 3:7] * np.array([frame_width, frame_height, frame_width, frame_height])\n",
        "                (x1, y1, x2, y2) = box.astype(\"int\")\n",
        "                center = np.array([(x1+x2)/2, (y1+y2)/2])\n",
        "\n",
        "                current_frame_detections.append((center, class_id))\n",
        "\n",
        "\n",
        "    if tracked_cars:\n",
        "\n",
        "        tracked_positions = [car['position'] for car in tracked_cars]\n",
        "        detected_positions = [det[0] for det in current_frame_detections]\n",
        "\n",
        "        detected_positions = np.array(detected_positions).reshape(-1, 2)\n",
        "        tracked_positions = np.array(tracked_positions).reshape(-1, 2)\n",
        "\n",
        "        distances = cdist(detected_positions, tracked_positions)\n",
        "\n",
        "        for det_idx, det in enumerate(current_frame_detections):\n",
        "            closest_tracked_idx = np.argmin(distances[det_idx])\n",
        "            distance = distances[det_idx, closest_tracked_idx]\n",
        "\n",
        "            if distance < 100:\n",
        "                tracked_cars[closest_tracked_idx]['position'] = det[0]\n",
        "                car_id = tracked_cars[closest_tracked_idx]['id']\n",
        "                if car_id not in tracked_car_ids:\n",
        "                    tmp_car_color = get_car_color(frame, box)\n",
        "                    color_counts[tmp_car_color] = color_counts.get(tmp_car_color, 0) + 1\n",
        "                    tracked_car_ids.add(car_id)\n",
        "\n",
        "            else:\n",
        "                car_id = car_id_counter\n",
        "                car_id_counter += 1\n",
        "                tracked_cars.append({'id': car_id, 'position': det[0]})\n",
        "\n",
        "            box = detections[0, 0, det_idx, 3:7] * np.array([frame_width, frame_height, frame_width, frame_height])\n",
        "            (x1, y1, x2, y2) = box.astype(\"int\")\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            car_color = get_car_color(frame, box)\n",
        "            label = f\"{class_names_dict[str(det[1])]} ID:{car_id} Color:{car_color}\"\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 255, 0), 2)\n",
        "\n",
        "    else:\n",
        "        for det in current_frame_detections:\n",
        "            car_id = car_id_counter\n",
        "            car_id_counter += 1\n",
        "            tracked_cars.append({'id': car_id, 'position': det[0]})\n",
        "\n",
        "    cv2.putText(frame, f\"Cars Detected: {len(tracked_cars)}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
        "    update_color_counts_display(frame, color_counts, display_start_pos=((frame_width - 400, 50)))\n",
        "\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "    #cv2.imshow(\"Frame\", frame)\n",
        "\n",
        "    #if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "    #    break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4ABnCTNtDSI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}